{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of Coding_logistic_regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il6Znbz7R-bz"
      },
      "source": [
        "# Sentiment analysis with Logistic Regression\n",
        "\n",
        "### Some plotting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOeTLDZTR_-2"
      },
      "source": [
        "!git clone https://github.com/s7s/machine_learning_1.git\n",
        "%cd  machine_learning_1/logistic_regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRr0Q1KKR-b5"
      },
      "source": [
        "# Importing packages\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAeOp-VVR-b6"
      },
      "source": [
        "import numpy as np\n",
        "features = np.array([[1,0],[0,2],[1,1],[1,2],[1,3],[2,2],[3,2],[2,3]])\n",
        "labels = np.array([0,0,0,0,1,1,1,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD55Gk4CR-b7"
      },
      "source": [
        "# Plotting the points\n",
        "utils.plot_points(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-Yf7M9jR-b8"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kydHv25YR-b9"
      },
      "source": [
        "def sigmoid(x):\n",
        "    ## TODO ##\n",
        "    # implement sigmoid function\n",
        "\n",
        "    return output\n",
        "\n",
        "def score(weights, bias, features):\n",
        "    return np.dot(weights, features) + bias\n",
        "\n",
        "def prediction(weights, bias, features):\n",
        "    ## TODO ##\n",
        "    # implement prediction calculation using sigmoid and score functions\n",
        "\n",
        "    return output\n",
        "\n",
        "def log_loss(weights, bias, features, label):\n",
        "    ## TODO ##\n",
        "    # implement log_loss calculation using prediction function\n",
        "\n",
        "    return output\n",
        "\n",
        "def total_log_loss(weights, bias, X, y):\n",
        "    total_error = 0\n",
        "    for i in range(len(X)):\n",
        "        total_error += log_loss(weights, bias, X[i], y[i])\n",
        "    return total_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29JrFSMKR-b9"
      },
      "source": [
        "def logistic_trick(weights, bias, features, label, learning_rate = 0.01):\n",
        "    ## TODO ##\n",
        "    # update the weights and bias using a single data sample\n",
        "\n",
        "    return weights, bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQGwdC2qR-b-"
      },
      "source": [
        "def logistic_regression_algorithm(features, labels, learning_rate = 0.01, epochs = 1000):\n",
        "    utils.plot_points(features, labels)\n",
        "    weights = [1.0 for i in range(len(features[0]))]\n",
        "    bias = 0.0\n",
        "    errors = []\n",
        "    for i in range(epochs):\n",
        "        # Comment the following line of code to remove the plots of all the classifiers\n",
        "        utils.draw_line(weights[0], weights[1], bias, color='grey', linewidth=0.1, linestyle='dotted')\n",
        "        errors.append(total_log_loss(weights, bias, features, labels))\n",
        "        j = random.randint(0, len(features)-1)\n",
        "        weights, bias = logistic_trick(weights, bias, features[j], labels[j])\n",
        "    utils.draw_line(weights[0], weights[1], bias)\n",
        "    plt.show()\n",
        "    plt.scatter(range(epochs), errors)\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('error')\n",
        "    return weights, bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDRk2mytR-b-"
      },
      "source": [
        "logistic_regression_algorithm(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmClMFaqR-b_"
      },
      "source": [
        "# Logistic SKlearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA3A3BVtR-b_"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "## TODO ##\n",
        "# Use SKlearn to train logistic regression\n",
        "clf="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhVzpskEhGg6"
      },
      "source": [
        "clf.score(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN-ld0NkR-b_"
      },
      "source": [
        "weights = clf.coef_\n",
        "bias = clf.intercept_\n",
        "utils.draw_line(weights[0][0], weights[0][1], bias)\n",
        "utils.plot_points(features, labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}